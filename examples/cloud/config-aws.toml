# LLM Shield API Configuration - AWS Deployment
# Deploy with: cargo run --features cloud-aws --example cloud-deploy -- --config examples/cloud/config-aws.toml

[server]
host = "0.0.0.0"
port = 8080
timeout_secs = 30
max_body_size = 10485760  # 10 MB
workers = 4

[auth]
enabled = true
jwt_secret = "${AWS_SECRET:llm-shield/jwt-secret}"  # Fetch from AWS Secrets Manager
jwt_expiration_secs = 3600
api_key_enabled = true

[rate_limit]
enabled = true
requests_per_second = 100
burst_size = 200

[rate_limit.tiers.free]
requests_per_minute = 60
requests_per_hour = 1000
concurrent_requests = 5

[rate_limit.tiers.pro]
requests_per_minute = 600
requests_per_hour = 10000
concurrent_requests = 50

[rate_limit.tiers.enterprise]
requests_per_minute = 6000
requests_per_hour = 100000
concurrent_requests = 500

[observability]
tracing_enabled = true
tracing_level = "info"
metrics_enabled = true
prometheus_port = 9090

[cache]
enabled = true
max_size = 10000
ttl_secs = 300

[models]
registry_path = "models/registry.json"
preload = true
preload_list = []

# AWS Cloud Configuration
[cloud]
enabled = true
provider = "aws"

[cloud.aws]
region = "us-east-1"  # Override with AWS_REGION env var

[cloud.aws.secrets]
enabled = true
cache_ttl_seconds = 300

[cloud.aws.storage]
enabled = true
bucket = "llm-shield-models"
prefix = "production/"

[cloud.aws.observability]
metrics_enabled = true
logs_enabled = true
namespace = "LLMShield/API"
log_group = "/aws/llm-shield/api"
log_stream = "production"
